{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as rsq\n",
    "import xgboost as xgb\n",
    "from feature_engine.categorical_encoders import OrdinalCategoricalEncoder\n",
    "from feature_engine.categorical_encoders import CountFrequencyCategoricalEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data(this data set not conataing null becoz we have imputed null vallues using cluster imputation)\n",
    "data=pd.read_csv(r\"data_no_null.csv\",encoding='latin1')# reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns not necessary for prediction\n",
    "cols_to_drop=['Unnamed: 0','sub_grade','State','Emp_designation','last_week_pay']\n",
    "# dropping the unnecessary columns\n",
    "df_xg=data.drop(columns=cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terms',\n",
       " 'grade',\n",
       " 'home_ownership',\n",
       " 'verification_status',\n",
       " 'purpose',\n",
       " 'initial_list_status',\n",
       " 'application_type',\n",
       " 'Experience']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = [col for col in df_xg.columns if df_xg[col].dtypes == 'O']\n",
    "\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xg[['purpose']] = df_xg[['purpose']].replace(['car','house','renewable_energy','wedding','vacation','moving','medical','educational'],\n",
    "                                              ['major_purchase','major_purchase','small_business','other','other','other','medical(or)education','medical(or)education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medical(or)education      8963\n",
       "small_business           10952\n",
       "major_purchase           29847\n",
       "home_improvement         51829\n",
       "other                    55391\n",
       "credit_card             206182\n",
       "debt_consolidation      524215\n",
       "Name: purpose, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.purpose.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_enc = CountFrequencyCategoricalEncoder(\n",
    "    encoding_method='frequency',\n",
    "    variables=categorical)\n",
    "\n",
    "df_xg_fre_enc = ordinal_enc.fit_transform(df_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xg_f=df_xg_fre_enc[['loan_amnt ', 'terms', 'Rate_of_intrst', 'grade', 'home_ownership',\n",
    "       'annual_inc', 'verification_status', 'purpose', 'debt_income_ratio',\n",
    "       'delinq_2yrs', 'inq_last_6mths', 'numb_credit', 'pub_rec',\n",
    "       'total_credits', 'initial_list_status',\n",
    "       'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
    "       'collection_recovery_fee', 'collections_12_mths_ex_med',\n",
    "       'application_type', 'acc_now_delinq', 'Experience',\n",
    "       'mths_since_last_delinq', 'tot_curr_bal', 'tot_colle_amt']]\n",
    "Y_xg_f=df_xg_fre_enc[['total revol_bal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((709903, 26), (177476, 26))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train_xg_f, X_test_xg_f, y_train_xg_f, y_test_xg_f = train_test_split(X_xg_f  ,  # predictors\n",
    "                                                    Y_xg_f,  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=2)  # seed to ensure reproducibility\n",
    "\n",
    "X_train_xg_f.shape, X_test_xg_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed: 25.5min remaining:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed: 33.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.1, 'gamma': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mod_f=xgb.XGBRegressor()\n",
    "params_f={\n",
    "        'learning_rate':[0.03,0.05,0.08,0.10,0.15,0.20,0.25,0.30],\n",
    "        'max_depth':[3,4,5,6,8,10,12,15,20,25],\n",
    "        'min_child_weight':[1,3,5,7],\n",
    "        'gamma':[0.0,0.1,0.2,0.3,0.4]\n",
    "        }\n",
    "random_search_f=RandomizedSearchCV(xgb_mod_f,param_distributions=params_f,n_iter=5,n_jobs=-1,cv=5,verbose=3)\n",
    "random_search_f.fit(X_train_xg_f,y_train_xg_f)\n",
    "random_search_f.best_estimator_\n",
    "random_search_f.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.2, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.05, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mod_f=xgb.XGBRegressor(min_child_weight=5, max_depth=8, learning_rate=0.05, gamma=0.2)\n",
    "xgb_mod_f.fit(X_train_xg_f,y_train_xg_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5071931802986467"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_pred_train_f=xgb_mod_f.predict(X_train_xg_f) \n",
    "xg_train_f_r2=rsq(y_train_xg_f,xg_pred_train_f)            \n",
    "xg_train_f_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44321916395818395"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_pred_test_f=xgb_mod_f.predict(X_test_xg_f)\n",
    "xg_test_f_r2=rsq(y_test_xg_f,xg_pred_test_f)\n",
    "xg_test_f_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R^2 : 0.5071931802986467\n",
      "test R^2 : 0.44321916395818395\n"
     ]
    }
   ],
   "source": [
    "print(\"train R^2 :\", xg_train_f_r2)\n",
    "print(\"test R^2 :\", xg_test_f_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train RMSE : 15685.77820466817\n",
      " test RMSE : 16978.15613094253\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(' train RMSE :', np.sqrt(metrics.mean_squared_error(y_train_xg_f,xg_pred_train_f)))\n",
    "print(' test RMSE :', np.sqrt(metrics.mean_squared_error(y_test_xg_f,xg_pred_test_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>feature importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>0.203006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terms</td>\n",
       "      <td>0.013979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rate_of_intrst</td>\n",
       "      <td>0.018982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grade</td>\n",
       "      <td>0.064061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home_ownership</td>\n",
       "      <td>0.031795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>0.072250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>verification_status</td>\n",
       "      <td>0.030308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>purpose</td>\n",
       "      <td>0.023990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>debt_income_ratio</td>\n",
       "      <td>0.062628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>delinq_2yrs</td>\n",
       "      <td>0.015159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inq_last_6mths</td>\n",
       "      <td>0.025046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>numb_credit</td>\n",
       "      <td>0.041374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pub_rec</td>\n",
       "      <td>0.034775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_credits</td>\n",
       "      <td>0.035791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>initial_list_status</td>\n",
       "      <td>0.021703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_rec_int</td>\n",
       "      <td>0.021673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>total_rec_late_fee</td>\n",
       "      <td>0.012924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recoveries</td>\n",
       "      <td>0.019967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>collection_recovery_fee</td>\n",
       "      <td>0.002787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>collections_12_mths_ex_med</td>\n",
       "      <td>0.008857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>application_type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>acc_now_delinq</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Experience</td>\n",
       "      <td>0.028595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mths_since_last_delinq</td>\n",
       "      <td>0.032711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tot_curr_bal</td>\n",
       "      <td>0.157711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tot_colle_amt</td>\n",
       "      <td>0.019929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       columns  feature importance\n",
       "0                   loan_amnt             0.203006\n",
       "1                        terms            0.013979\n",
       "2               Rate_of_intrst            0.018982\n",
       "3                        grade            0.064061\n",
       "4               home_ownership            0.031795\n",
       "5                   annual_inc            0.072250\n",
       "6          verification_status            0.030308\n",
       "7                      purpose            0.023990\n",
       "8            debt_income_ratio            0.062628\n",
       "9                  delinq_2yrs            0.015159\n",
       "10              inq_last_6mths            0.025046\n",
       "11                 numb_credit            0.041374\n",
       "12                     pub_rec            0.034775\n",
       "13               total_credits            0.035791\n",
       "14         initial_list_status            0.021703\n",
       "15               total_rec_int            0.021673\n",
       "16          total_rec_late_fee            0.012924\n",
       "17                  recoveries            0.019967\n",
       "18     collection_recovery_fee            0.002787\n",
       "19  collections_12_mths_ex_med            0.008857\n",
       "20            application_type            0.000000\n",
       "21              acc_now_delinq            0.000000\n",
       "22                  Experience            0.028595\n",
       "23      mths_since_last_delinq            0.032711\n",
       "24                tot_curr_bal            0.157711\n",
       "25               tot_colle_amt            0.019929"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_xg_f=list(xgb_mod_f.feature_importances_)\n",
    "j_xg_f=list(X_train_xg_f.columns)\n",
    "data_xg_f ={'columns': j_xg_f, 'feature importance':k_xg_f}\n",
    "d_xg_f=pd.DataFrame(data_xg_f)\n",
    "d_xg_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### so here i m droping the features whose importance is less than 1% :-\n",
    "collection_recovery_fee\n",
    "\n",
    "collections_12_mths_ex_med\n",
    "\n",
    "application_type\n",
    "\n",
    "acc_now_delinq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xg_f_1=df_xg_fre_enc[['loan_amnt ', 'terms', 'Rate_of_intrst', 'grade', 'home_ownership','annual_inc', 'verification_status',\n",
    "                        'purpose', 'debt_income_ratio','delinq_2yrs', 'inq_last_6mths', 'numb_credit', 'pub_rec', 'total_credits', \n",
    "                        'initial_list_status','total_rec_int', 'total_rec_late_fee', 'recoveries','Experience','mths_since_last_delinq', \n",
    "                        'tot_curr_bal', 'tot_colle_amt']]\n",
    "Y_xg_f_1=df_xg_fre_enc[['total revol_bal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((621165, 22), (266214, 22))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train_xg_f_1, X_test_xg_f_1, y_train_xg_f_1, y_test_xg_f_1 = train_test_split(X_xg_f_1,# predictors\n",
    "                                                    Y_xg_f_1, # target\n",
    "    test_size=0.30,  # percentage of obs in test set\n",
    "    random_state=2)  # seed to ensure reproducibility\n",
    "\n",
    "X_train_xg_f_1.shape, X_test_xg_f_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.2, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.05, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mod_f_1=xgb.XGBRegressor(min_child_weight=5, max_depth=8, learning_rate=0.05, gamma=0.2)\n",
    "xgb_mod_f_1.fit(np.array(X_train_xg_f_1),np.array(y_train_xg_f_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pred_train_f_1=xgb_mod_f_1.predict(np.array(X_train_xg_f_1)) \n",
    "xg_train_f_1_r2=rsq(y_train_xg_f_1,xg_pred_train_f_1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pred_test_f_1=xgb_mod_f_1.predict(np.array(X_test_xg_f_1)) \n",
    "xg_test_f_1_r2=rsq(y_test_xg_f_1,xg_pred_test_f_1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R^2 : 0.5170709398659196\n",
      "test R^2 : 0.408121832094141\n"
     ]
    }
   ],
   "source": [
    "print(\"train R^2 :\", xg_train_f_1_r2)\n",
    "print(\"test R^2 :\", xg_test_f_1_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train RMSE : 15678.323911768333\n",
      " test RMSE : 17010.384081760752\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(' train RMSE :', np.sqrt(metrics.mean_squared_error(y_train_xg_f_1,xg_pred_train_f_1)))\n",
    "print(' test RMSE :', np.sqrt(metrics.mean_squared_error(y_test_xg_f_1,xg_pred_test_f_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>feature importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>0.205232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terms</td>\n",
       "      <td>0.018222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rate_of_intrst</td>\n",
       "      <td>0.018566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grade</td>\n",
       "      <td>0.070319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home_ownership</td>\n",
       "      <td>0.029284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>0.071329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>verification_status</td>\n",
       "      <td>0.029433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>purpose</td>\n",
       "      <td>0.022427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>debt_income_ratio</td>\n",
       "      <td>0.060378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>delinq_2yrs</td>\n",
       "      <td>0.014879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inq_last_6mths</td>\n",
       "      <td>0.024913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>numb_credit</td>\n",
       "      <td>0.042609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pub_rec</td>\n",
       "      <td>0.033473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_credits</td>\n",
       "      <td>0.029468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>initial_list_status</td>\n",
       "      <td>0.024772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_rec_int</td>\n",
       "      <td>0.021381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>total_rec_late_fee</td>\n",
       "      <td>0.010554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recoveries</td>\n",
       "      <td>0.025578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Experience</td>\n",
       "      <td>0.028807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mths_since_last_delinq</td>\n",
       "      <td>0.032403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tot_curr_bal</td>\n",
       "      <td>0.165524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tot_colle_amt</td>\n",
       "      <td>0.020448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   columns  feature importance\n",
       "0               loan_amnt             0.205232\n",
       "1                    terms            0.018222\n",
       "2           Rate_of_intrst            0.018566\n",
       "3                    grade            0.070319\n",
       "4           home_ownership            0.029284\n",
       "5               annual_inc            0.071329\n",
       "6      verification_status            0.029433\n",
       "7                  purpose            0.022427\n",
       "8        debt_income_ratio            0.060378\n",
       "9              delinq_2yrs            0.014879\n",
       "10          inq_last_6mths            0.024913\n",
       "11             numb_credit            0.042609\n",
       "12                 pub_rec            0.033473\n",
       "13           total_credits            0.029468\n",
       "14     initial_list_status            0.024772\n",
       "15           total_rec_int            0.021381\n",
       "16      total_rec_late_fee            0.010554\n",
       "17              recoveries            0.025578\n",
       "18              Experience            0.028807\n",
       "19  mths_since_last_delinq            0.032403\n",
       "20            tot_curr_bal            0.165524\n",
       "21           tot_colle_amt            0.020448"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_xg_f_1=list(xgb_mod_f_1.feature_importances_)\n",
    "j_xg_f_1=list(X_train_xg_f_1.columns)\n",
    "data_xg_f_1 ={'columns': j_xg_f_1, 'feature importance':k_xg_f_1}\n",
    "d_xg_f_1=pd.DataFrame(data_xg_f_1)\n",
    "d_xg_f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(xgb_mod_f_1,open('finalized_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27230.615 14566.864 52932.723 ... 18900.77  20298.232 23070.572]\n"
     ]
    }
   ],
   "source": [
    "# prediction using the saved model.\n",
    "loaded_model = pickle.load(open('finalized_model.pkl', 'rb'))\n",
    "prediction=loaded_model.predict(np.array(X_test_xg_f_1))\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.NO</th>\n",
       "      <th>total revol_bal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [S.NO, total revol_bal]\n",
       "Index: []"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.DataFrame(columns = ['S.NO', 'total revol_bal'])\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = []\n",
    "len_pred = prediction.size +1\n",
    "for x in range(1,len_pred):\n",
    "    list_1.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv['S.NO'] = list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv['total revol_bal'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.NO</th>\n",
       "      <th>total revol_bal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27230.615234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14566.864258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>52932.722656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17604.496094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7046.140137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266209</th>\n",
       "      <td>266210</td>\n",
       "      <td>7584.052246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266210</th>\n",
       "      <td>266211</td>\n",
       "      <td>10931.376953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266211</th>\n",
       "      <td>266212</td>\n",
       "      <td>18900.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266212</th>\n",
       "      <td>266213</td>\n",
       "      <td>20298.232422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266213</th>\n",
       "      <td>266214</td>\n",
       "      <td>23070.572266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266214 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          S.NO  total revol_bal\n",
       "0            1     27230.615234\n",
       "1            2     14566.864258\n",
       "2            3     52932.722656\n",
       "3            4     17604.496094\n",
       "4            5      7046.140137\n",
       "...        ...              ...\n",
       "266209  266210      7584.052246\n",
       "266210  266211     10931.376953\n",
       "266211  266212     18900.769531\n",
       "266212  266213     20298.232422\n",
       "266213  266214     23070.572266\n",
       "\n",
       "[266214 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.to_csv('final_prediction_csv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### so above one is showing our saved model is working fine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"terms\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['terms'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['terms']].values\n",
    "temp_values = a.fit_transform(df_xg[['terms']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['terms'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"terms.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'terms': {'36 months': 0.699954585357553, '60 months': 0.30004541464244705}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"terms.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"grade\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['grade'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['grade']].values\n",
    "temp_values = b.fit_transform(df_xg[['grade']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['grade'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"grade.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grade': {'E': 0.07967846883913186, 'B': 0.2868391070782608, 'A': 0.16701093895618446, 'D': 0.15725186194399463, 'C': 0.27706312635300134, 'F': 0.025970864760153214, 'G': 0.00618563206927367}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"grade.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"home_ownership\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['home_ownership'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['home_ownership']].values\n",
    "temp_values = c.fit_transform(df_xg[['home_ownership']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['home_ownership'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"home_ownership.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'home_ownership': {'OWN': 0.09857118547993586, 'MORTGAGE': 0.49985068386788506, 'RENT': 0.4013133058140885, 'OTHER': 0.00020509838524463618, 'NONE': 5.6345710232042906e-05, 'ANY': 3.3807426139225743e-06}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"home_ownership.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANY              3\n",
       "MORTGAGE    443557\n",
       "NONE            50\n",
       "OTHER          182\n",
       "OWN          87470\n",
       "RENT        356117\n",
       "Name: home_ownership, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.home_ownership.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"verification_status\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['verification_status'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['verification_status']].values\n",
    "temp_values = d.fit_transform(df_xg[['verification_status']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['verification_status'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"verification_status.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verification_status': {'Source Verified': 0.3713835914530319, 'Not Verified': 0.3006043640879489, 'Verified': 0.3280120444590192}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"verification_status.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Verified       266750\n",
       "Source Verified    329558\n",
       "Verified           291071\n",
       "Name: verification_status, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.verification_status.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"purpose\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['purpose'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['purpose']].values\n",
    "temp_values = e.fit_transform(df_xg[['purpose']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['purpose'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"purpose.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'purpose': {'debt_consolidation': 0.5907453297858074, 'home_improvement': 0.05840683631233103, 'credit_card': 0.2323494245412614, 'other': 0.06242090470926177, 'major_purchase': 0.03363500826591569, 'small_business': 0.012341964369226677, 'medical(or)education': 0.01010053201619601}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"purpose.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_card             206182\n",
       "debt_consolidation      524215\n",
       "home_improvement         51829\n",
       "major_purchase           29847\n",
       "medical(or)education      8963\n",
       "other                    55391\n",
       "small_business           10952\n",
       "Name: purpose, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.purpose.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"initial_list_status\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['initial_list_status'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['initial_list_status']].values\n",
    "temp_values = f.fit_transform(df_xg[['initial_list_status']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['initial_list_status'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"initial_list_status.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial_list_status': {'f': 0.5148285005617668, 'w': 0.4851714994382333}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"initial_list_status.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    456848\n",
       "w    430531\n",
       "Name: initial_list_status, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.initial_list_status.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"Experience\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['Experience'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['Experience']].values\n",
    "temp_values = g.fit_transform(df_xg[['Experience']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['Experience'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"Experience.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Experience': {'9 years': 0.03905546559023822, '< 1 year': 0.07956577741866779, '2 years': 0.08887972332002447, '10+ years': 0.37908717695595684, '5 years': 0.06277362885531436, '8 years': 0.049533513864988915, '7 years': 0.05025361204175442, '4 years': 0.059195676255579636, '1 year': 0.06434116651396979, '3 years': 0.07891329409418073, '6 years': 0.04840096508932486}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"Experience.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 year        57095\n",
       "10+ years    336394\n",
       "2 years       78870\n",
       "3 years       70026\n",
       "4 years       52529\n",
       "5 years       55704\n",
       "6 years       42950\n",
       "7 years       44594\n",
       "8 years       43955\n",
       "9 years       34657\n",
       "< 1 year      70605\n",
       "Name: Experience, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.Experience.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
